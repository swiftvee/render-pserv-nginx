daemon off;

# TODO: Investigate how many cores do the Render instances we use for this have
# and adjust this setting accordingly
worker_processes 2;

# https://stackoverflow.com/questions/22541333/have-nginx-access-log-and-error-log-log-to-stdout-and-stderr-of-master-process
error_log /dev/stdout warn;

events {
  use epoll;
  worker_connections 1024;
}

http {
  include mime.types;

  server_tokens off;

  log_format l2met 'measure#nginx.service=$request_time request_id=$http_x_request_id';

  access_log on;
  access_log /dev/stdout;

  # Pass the real client IP address from stacks like Render, Heroku
  # to Rails.
  set_real_ip_from 0.0.0.0/0;
  real_ip_header X-Forwarded-For;
  real_ip_recursive off;

  # Set up zones and caches for basic DDOS mitigation.
  # See the app_server block for how to actually enable these. 
  # All of the values below are some reasonable defaults but require tweakign and testing based on your scenario.
  # Based on http://bitsandpieces.it/nginx-by-examples-dos-protection

  # Connection Limiting
  # It is a sensitive precaution to avoid too many connections from a single IP and itâ€™s first line of defence against trivial DOS attacks (i.e. a simple script flooding our backend from 1 server with 1 IP)
  limit_conn_zone $binary_remote_addr zone=rails_connections:30m;

  # Rate Limiting
  # Rate limiting works very similarly to connection limiting but from the perspective of how many requests per second are accepted by a single IP address
  # The 5 requests per second rate has been determined by testing a performance-l dyno. At this rate, a script can hammer the homepage as fast as possible from one IP, while on another IP I was able to use the site without any issues. Note that visitors will be unlikely to run into this limitation, as in production we have a minimum of 4 different servers, so the load will be spread.
  #
  # logs ca then be watched using query:
  #   "delaying request" OR "limiting requests"
  #
  limit_req_zone $binary_remote_addr zone=rails:30m rate=5r/s;
  limit_req_status 503;

  # Basic POST (and other requests that usually carry payload or modify state) request limiting
  # https://product.reverb.com/first-line-of-defense-blocking-bad-post-requests-using-nginx-rate-limiting-507f4c6eed7b
  # Maps ip address to $post_limit variable if request is of type POST
  map $request_method $post_limit {
    default         "";
    POST            $binary_remote_addr;
    PUT             $binary_remote_addr;
    DELETE          $binary_remote_addr;
  }
  limit_req_zone $post_limit zone=post_requests:30m rate=2r/s;

  default_type application/octet-stream;
  sendfile on;

  # Must read the body in 5 seconds.
  client_body_timeout 5;

  gzip on;
  gzip_http_version 1.1;
  gzip_proxied any;
  gzip_types
    application/atom+xml
    application/javascript
    application/json
    application/ld+json
    application/manifest+json
    application/rss+xml
    application/vnd.geo+json
    application/vnd.ms-fontobject
    application/x-font-ttf
    application/x-web-app-manifest+json
    application/xhtml+xml
    application/xml
    font/opentype
    image/bmp
    image/svg+xml
    image/x-icon
    text/cache-manifest
    text/css
    text/plain
    text/vcard
    text/vnd.rim.location.xloc
    text/vtt
    text/x-component
    text/x-cross-domain-policy;

  # https://www.nginx.com/blog/websocket-nginx/
  map $http_upgrade $connection_upgrade {
      default Upgrade;
      ''      close;
  }
  
  upstream app_server {
    server unix:/tmp/nginx.socket fail_timeout=0;
  }

  server {
    listen 80 default_server;
    server_name _;
    
    # Default app location on Heroku. Change as needed.
    root /app/public;

    # The app behind the proxy can use this to change it's Host ENV variable, so that it can generate correct full URLs
    # Rails has build in support for X-Forwarded-Host header
    # Writing to these headers also protects against attacker trying to supply them in the request
    proxy_set_header X-Forwarded-Host $host;
    proxy_set_header X-Forwarded-Server $host;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    # Needs to match gzip_http_version (above), so that proxied requests are gzipped too
    proxy_http_version 1.1;

    # Custom error pages
    error_page 404 /404.html;
    error_page 422 /422.html;
    error_page 500 /500.html;
    # 503 is raised if nginx needs to rate limit you.
    # error_page 503 /503.html;
    # Bad Gateway can happen if all Puma processes are occupied.
    # That means server overload which is what 503.html is for.
    # error_page 502 /503.html;

    try_files $uri/index.html $uri @app;

    location @app {
      proxy_set_header Host $http_host;
      proxy_set_header Connection "";
      proxy_redirect off;
      proxy_pass http://app_server;

      # Uncomment bellow to enable. 
      # Remember to tweak and test the values that your scenario requires.
      # limit_conn rails_connections 600;
      # limit_req zone=rails burst=20;
      # limit_req zone=post_requests burst=5;
    }
    
    # Action Cable
    # https://www.nginx.com/blog/websocket-nginx/
    location = /cable {
      proxy_pass http://app_server;
      proxy_set_header Upgrade $http_upgrade;
      proxy_set_header Connection $connection_upgrade;
      proxy_set_header Host $http_host;
    }

    # Standards Rails assets location
    # These files should be served directly by nginx and cached forever,
    # because filenames are always unique, due to checksum.
    location /assets/ {
      expires max;
      add_header Cache-Control public;
      gzip_static on;
    }

    # Webpacker packs
    location /packs/ {
      expires max;
      add_header Cache-Control public;
      gzip_static on;
    }
  }
}
